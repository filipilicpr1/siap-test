{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:07.381059Z",
     "iopub.status.busy": "2024-03-29T13:27:07.380622Z",
     "iopub.status.idle": "2024-03-29T13:27:11.572086Z",
     "shell.execute_reply": "2024-03-29T13:27:11.571326Z",
     "shell.execute_reply.started": "2024-03-29T13:27:07.381017Z"
    },
    "id": "ARtra4A05zOp",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from nltk.stem import PorterStemmer\n",
    "from torch.utils.data import TensorDataset, DataLoader,random_split\n",
    "from transformers import BertForSequenceClassification, AdamW,BertTokenizerFast,get_linear_schedule_with_warmup\n",
    "from sklearn.metrics import classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:11.582466Z",
     "iopub.status.busy": "2024-03-29T13:27:11.582174Z",
     "iopub.status.idle": "2024-03-29T13:27:11.753964Z",
     "shell.execute_reply": "2024-03-29T13:27:11.753214Z",
     "shell.execute_reply.started": "2024-03-29T13:27:11.582413Z"
    },
    "id": "uO1gzfyX5zOs",
    "outputId": "0f25f020-92b6-4845-9843-3c79688dd685",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:11.757758Z",
     "iopub.status.busy": "2024-03-29T13:27:11.757493Z",
     "iopub.status.idle": "2024-03-29T13:27:12.944325Z",
     "shell.execute_reply": "2024-03-29T13:27:12.943604Z",
     "shell.execute_reply.started": "2024-03-29T13:27:11.757736Z"
    },
    "id": "7M97Yl4z5zOt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/preprocessed_data_bert.csv\")\n",
    "\n",
    "def map_popularity(value):\n",
    "    if value == \"super positiv\":\n",
    "        return 0\n",
    "    elif value == \"positiv\":\n",
    "        return 1\n",
    "    elif value == \"negativ\":\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "df[\"popularity\"] = df[\"popularity\"].apply(map_popularity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 614
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:12.945559Z",
     "iopub.status.busy": "2024-03-29T13:27:12.945254Z",
     "iopub.status.idle": "2024-03-29T13:27:12.960428Z",
     "shell.execute_reply": "2024-03-29T13:27:12.959507Z",
     "shell.execute_reply.started": "2024-03-29T13:27:12.945534Z"
    },
    "id": "7luXWQuQAs8H",
    "outputId": "980f86a8-724d-48cc-b6c5-e8d10205cfe0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>video_id</th>\n",
       "      <th>popularity</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>--14w5SOEUs</td>\n",
       "      <td>1</td>\n",
       "      <td>Channel with title : MigosVEVO has posted vide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>--40TEbZ9Is</td>\n",
       "      <td>1</td>\n",
       "      <td>Channel with title : Television Academy has po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-0PZSxZuAXQ</td>\n",
       "      <td>1</td>\n",
       "      <td>Channel with title : Breakfast Club Power 105....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0QSEZIqVWc</td>\n",
       "      <td>1</td>\n",
       "      <td>Channel with title : VarietyJay has posted vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-0Yxqcm0K2I</td>\n",
       "      <td>1</td>\n",
       "      <td>Channel with title : TheMacLife has posted vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67244</th>\n",
       "      <td>79956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Channel with title : SpaceX has posted video w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67245</th>\n",
       "      <td>79957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Channel with title : Inside Edition has posted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67246</th>\n",
       "      <td>79958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>Channel with title : Thomas Bikias has posted ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67247</th>\n",
       "      <td>79959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Channel with title : Saturday Night Live has p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67248</th>\n",
       "      <td>79960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Channel with title : Molly Burke has posted vi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67249 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     video_id  popularity  \\\n",
       "0               0  --14w5SOEUs           1   \n",
       "1               1  --40TEbZ9Is           1   \n",
       "2               2  -0PZSxZuAXQ           1   \n",
       "3               3  -0QSEZIqVWc           1   \n",
       "4               4  -0Yxqcm0K2I           1   \n",
       "...           ...          ...         ...   \n",
       "67244       79956          NaN           0   \n",
       "67245       79957          NaN           3   \n",
       "67246       79958          NaN           3   \n",
       "67247       79959          NaN           1   \n",
       "67248       79960          NaN           0   \n",
       "\n",
       "                                                sentence  \n",
       "0      Channel with title : MigosVEVO has posted vide...  \n",
       "1      Channel with title : Television Academy has po...  \n",
       "2      Channel with title : Breakfast Club Power 105....  \n",
       "3      Channel with title : VarietyJay has posted vid...  \n",
       "4      Channel with title : TheMacLife has posted vid...  \n",
       "...                                                  ...  \n",
       "67244  Channel with title : SpaceX has posted video w...  \n",
       "67245  Channel with title : Inside Edition has posted...  \n",
       "67246  Channel with title : Thomas Bikias has posted ...  \n",
       "67247  Channel with title : Saturday Night Live has p...  \n",
       "67248  Channel with title : Molly Burke has posted vi...  \n",
       "\n",
       "[67249 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:13.310699Z",
     "iopub.status.busy": "2024-03-29T13:27:13.310308Z",
     "iopub.status.idle": "2024-03-29T13:27:13.314198Z",
     "shell.execute_reply": "2024-03-29T13:27:13.313471Z",
     "shell.execute_reply.started": "2024-03-29T13:27:13.310672Z"
    },
    "id": "2CLrs5ss5zOt",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = df.sentence.values\n",
    "popularities = df.popularity.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:14.910778Z",
     "iopub.status.busy": "2024-03-29T13:27:14.910383Z",
     "iopub.status.idle": "2024-03-29T13:27:15.013695Z",
     "shell.execute_reply": "2024-03-29T13:27:15.013061Z",
     "shell.execute_reply.started": "2024-03-29T13:27:14.910753Z"
    },
    "id": "8bA0TGbT5zOu",
    "outputId": "067fad16-4697-4318-9aa7-b016cbdf8690",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:16.670751Z",
     "iopub.status.busy": "2024-03-29T13:27:16.670349Z",
     "iopub.status.idle": "2024-03-29T13:27:16.677316Z",
     "shell.execute_reply": "2024-03-29T13:27:16.676484Z",
     "shell.execute_reply.started": "2024-03-29T13:27:16.670722Z"
    },
    "id": "FtxYhXsU5zOv",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tokenize_funciton(text) :\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sentence in text:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=512,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_input_ids = [stemmer.stem(token) for token in tokenizer.convert_ids_to_tokens(encoded_dict['input_ids'][0].tolist())]\n",
    "        stemmed_input_ids = tokenizer.convert_tokens_to_ids(stemmed_input_ids)\n",
    "\n",
    "        encoded_dict['input_ids'] = torch.tensor(stemmed_input_ids).unsqueeze(0)\n",
    "\n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "\n",
    "    return input_ids, attention_masks\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:18.966758Z",
     "iopub.status.busy": "2024-03-29T13:27:18.966359Z",
     "iopub.status.idle": "2024-03-29T13:27:18.990542Z",
     "shell.execute_reply": "2024-03-29T13:27:18.989822Z",
     "shell.execute_reply.started": "2024-03-29T13:27:18.966731Z"
    },
    "id": "EbxdJSQG2WhT",
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels = np.array(popularities, dtype=object)\n",
    "labels = np.array(labels, dtype=np.int64)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T13:27:20.358949Z",
     "iopub.status.busy": "2024-03-29T13:27:20.358521Z",
     "iopub.status.idle": "2024-03-29T13:37:33.383076Z",
     "shell.execute_reply": "2024-03-29T13:37:33.382417Z",
     "shell.execute_reply.started": "2024-03-29T13:27:20.358920Z"
    },
    "id": "AGra__fB2WhU",
    "outputId": "6ea378a8-9fee-4814-a8fe-5146f66a1c25",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2688: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_masks = tokenize_funciton(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T13:38:36.342945Z",
     "iopub.status.busy": "2024-03-29T13:38:36.342480Z",
     "iopub.status.idle": "2024-03-29T13:38:36.389341Z",
     "shell.execute_reply": "2024-03-29T13:38:36.388442Z",
     "shell.execute_reply.started": "2024-03-29T13:38:36.342915Z"
    },
    "id": "MaY_qMk85zOv",
    "outputId": "fe9ce892-ba80-407d-c051-c54bd0ab04ca",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training data : 53799\n",
      "Length of validating data : 13450\n"
     ]
    }
   ],
   "source": [
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "train_data_size = int(0.8 * len(dataset))\n",
    "validation_data_size = int(len(dataset) - train_data_size)\n",
    "\n",
    "train_dataset, validating_dataset = random_split(dataset, [train_data_size, validation_data_size])\n",
    "\n",
    "print('Length of training data : ' + str(train_data_size))\n",
    "print('Length of validating data : ' + str(validation_data_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:41:19.060766Z",
     "iopub.status.busy": "2024-03-29T13:41:19.060371Z",
     "iopub.status.idle": "2024-03-29T13:41:19.065004Z",
     "shell.execute_reply": "2024-03-29T13:41:19.064264Z",
     "shell.execute_reply.started": "2024-03-29T13:41:19.060738Z"
    },
    "id": "vZQHcHD8_zjn",
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_params = {'batch_size': 8,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "val_params = {'batch_size': 8,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(train_dataset, **train_params)\n",
    "validating_loader = DataLoader(validating_dataset, **val_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:41:21.430680Z",
     "iopub.status.busy": "2024-03-29T13:41:21.430278Z",
     "iopub.status.idle": "2024-03-29T13:41:21.435249Z",
     "shell.execute_reply": "2024-03-29T13:41:21.434344Z",
     "shell.execute_reply.started": "2024-03-29T13:41:21.430652Z"
    },
    "id": "pm9sKwxN2WhU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTModel, self).__init__()\n",
    "        self.model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",num_labels = 4)\n",
    "\n",
    "    def forward(self, ids, mask, b_labels):\n",
    "        output = self.model(ids,token_type_ids=None,attention_mask=mask,labels=b_labels)\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T13:41:24.116915Z",
     "iopub.status.busy": "2024-03-29T13:41:24.116507Z",
     "iopub.status.idle": "2024-03-29T13:41:24.768734Z",
     "shell.execute_reply": "2024-03-29T13:41:24.767906Z",
     "shell.execute_reply.started": "2024-03-29T13:41:24.116889Z"
    },
    "id": "kMpSJIBB2WhV",
    "outputId": "c4231890-0a4b-4a6a-fced-4cdc1b0d2cbf",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTModel(\n",
       "  (model): BertForSequenceClassification(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BERTModel()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T13:41:28.293342Z",
     "iopub.status.busy": "2024-03-29T13:41:28.292935Z",
     "iopub.status.idle": "2024-03-29T13:41:28.572892Z",
     "shell.execute_reply": "2024-03-29T13:41:28.572160Z",
     "shell.execute_reply.started": "2024-03-29T13:41:28.293315Z"
    },
    "id": "XJ0oS40j5zOx",
    "outputId": "6bb099a3-80f0-4e70-dd5e-f7d45cfad037",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(),lr = 2e-5,eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:41:30.230610Z",
     "iopub.status.busy": "2024-03-29T13:41:30.230206Z",
     "iopub.status.idle": "2024-03-29T13:41:30.234729Z",
     "shell.execute_reply": "2024-03-29T13:41:30.233868Z",
     "shell.execute_reply.started": "2024-03-29T13:41:30.230581Z"
    },
    "id": "G3mGEmHl5zOx",
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 4\n",
    "\n",
    "num_steps_for_training = len(training_loader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 0,num_training_steps = num_steps_for_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T13:41:31.941198Z",
     "iopub.status.busy": "2024-03-29T13:41:31.940686Z",
     "iopub.status.idle": "2024-03-29T13:41:31.945483Z",
     "shell.execute_reply": "2024-03-29T13:41:31.944653Z",
     "shell.execute_reply.started": "2024-03-29T13:41:31.941166Z"
    },
    "id": "wMxBKgrA2WhW",
    "tags": []
   },
   "outputs": [],
   "source": [
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "np.random.seed(seed_value)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-03-29T13:41:33.679006Z",
     "iopub.status.busy": "2024-03-29T13:41:33.678612Z",
     "iopub.status.idle": "2024-03-29T19:07:33.168438Z",
     "shell.execute_reply": "2024-03-29T19:07:33.167646Z",
     "shell.execute_reply.started": "2024-03-29T13:41:33.678978Z"
    },
    "id": "W9cacUuM5zOz",
    "outputId": "f0dfe46c-ba6e-457f-f105-4f1e1b9d8fd8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "\n",
      "Training : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.45      0.42      9666\n",
      "           1       0.63      0.62      0.63     19180\n",
      "           2       0.50      0.49      0.49     16097\n",
      "           3       0.59      0.56      0.57      8856\n",
      "\n",
      "    accuracy                           0.54     53799\n",
      "   macro avg       0.53      0.53      0.53     53799\n",
      "weighted avg       0.54      0.54      0.54     53799\n",
      "\n",
      "\n",
      "Training loss: 1.0271483793001637\n",
      "\n",
      "\n",
      "Validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.50      0.51      2440\n",
      "           1       0.69      0.65      0.67      4824\n",
      "           2       0.60      0.54      0.57      4067\n",
      "           3       0.56      0.75      0.64      2119\n",
      "\n",
      "    accuracy                           0.61     13450\n",
      "   macro avg       0.59      0.61      0.60     13450\n",
      "weighted avg       0.61      0.61      0.61     13450\n",
      "\n",
      "\n",
      "Evaluating loss: 0.9272671154479847\n",
      "\n",
      "\n",
      "Accuracy: 0.6067657992565055\n",
      "\n",
      "Epoch 2\n",
      "\n",
      "Training : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.58      0.56      9666\n",
      "           1       0.68      0.70      0.69     19180\n",
      "           2       0.64      0.57      0.60     16097\n",
      "           3       0.70      0.72      0.71      8856\n",
      "\n",
      "    accuracy                           0.64     53799\n",
      "   macro avg       0.64      0.64      0.64     53799\n",
      "weighted avg       0.64      0.64      0.64     53799\n",
      "\n",
      "\n",
      "Training loss: 0.8503890234143318\n",
      "\n",
      "\n",
      "Validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.45      0.51      2440\n",
      "           1       0.66      0.75      0.70      4824\n",
      "           2       0.60      0.60      0.60      4067\n",
      "           3       0.70      0.68      0.69      2119\n",
      "\n",
      "    accuracy                           0.64     13450\n",
      "   macro avg       0.64      0.62      0.63     13450\n",
      "weighted avg       0.64      0.64      0.64     13450\n",
      "\n",
      "\n",
      "Evaluating loss: 0.8620406225385692\n",
      "\n",
      "\n",
      "Accuracy: 0.6397026022304833\n",
      "\n",
      "Epoch 3\n",
      "\n",
      "Training : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.68      9666\n",
      "           1       0.73      0.78      0.75     19180\n",
      "           2       0.74      0.66      0.69     16097\n",
      "           3       0.79      0.79      0.79      8856\n",
      "\n",
      "    accuracy                           0.73     53799\n",
      "   macro avg       0.73      0.73      0.73     53799\n",
      "weighted avg       0.73      0.73      0.73     53799\n",
      "\n",
      "\n",
      "Training loss: 0.686926813626378\n",
      "\n",
      "\n",
      "Validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59      2440\n",
      "           1       0.68      0.76      0.72      4824\n",
      "           2       0.69      0.55      0.61      4067\n",
      "           3       0.69      0.73      0.71      2119\n",
      "\n",
      "    accuracy                           0.66     13450\n",
      "   macro avg       0.66      0.66      0.66     13450\n",
      "weighted avg       0.67      0.66      0.66     13450\n",
      "\n",
      "\n",
      "Evaluating loss: 0.8722859817987815\n",
      "\n",
      "\n",
      "Accuracy: 0.6635687732342007\n",
      "\n",
      "Epoch 4\n",
      "\n",
      "Training : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.78      0.78      9666\n",
      "           1       0.78      0.84      0.81     19180\n",
      "           2       0.82      0.74      0.78     16097\n",
      "           3       0.86      0.85      0.85      8856\n",
      "\n",
      "    accuracy                           0.80     53799\n",
      "   macro avg       0.81      0.80      0.80     53799\n",
      "weighted avg       0.80      0.80      0.80     53799\n",
      "\n",
      "\n",
      "Training loss: 0.5310552442960137\n",
      "\n",
      "\n",
      "Validation :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.58      0.59      2440\n",
      "           1       0.68      0.76      0.72      4824\n",
      "           2       0.68      0.58      0.63      4067\n",
      "           3       0.70      0.72      0.71      2119\n",
      "\n",
      "    accuracy                           0.67     13450\n",
      "   macro avg       0.66      0.66      0.66     13450\n",
      "weighted avg       0.67      0.67      0.67     13450\n",
      "\n",
      "\n",
      "Evaluating loss: 0.9656877175048791\n",
      "\n",
      "\n",
      "Accuracy: 0.6672862453531598\n"
     ]
    }
   ],
   "source": [
    "best_accuracy=0\n",
    "for i in range(0, epochs):\n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "    print('\\nEpoch ' + str(i+1))\n",
    "    print('\\nTraining : ')\n",
    "\n",
    "    loss = 0\n",
    "    model.train()\n",
    "    for step,data in enumerate(training_loader,0):\n",
    "        ids = data[0].to(device)\n",
    "        mask = data[1].to(device)\n",
    "        targets = data[2].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model.forward(ids, mask, targets)\n",
    "        current_loss = output.loss\n",
    "        loss += current_loss.item()\n",
    "        current_loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        logits = output.logits\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "        target_ids = targets.to('cpu').numpy()\n",
    "\n",
    "        predictions.extend(list(pred_flat))\n",
    "        ground_truth.extend(list(target_ids.flatten()))\n",
    "\n",
    "    print(classification_report(ground_truth,predictions,labels=[0,1,2,3]))\n",
    "\n",
    "    print(\"\\nTraining loss: \" + str(loss/len(training_loader)) + \"\\n\")\n",
    "\n",
    "    print(\"\\nValidation :\")\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        ground_truth = []\n",
    "        for _,data in enumerate(validating_loader,0):\n",
    "\n",
    "            ids = data[0].to(device)\n",
    "            mask = data[1].to(device)\n",
    "            targets = data[2].to(device)\n",
    "\n",
    "            output = model.forward(ids, mask, targets)\n",
    "\n",
    "            eval_loss += output.loss.item()\n",
    "\n",
    "            logits = output.logits\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            target_ids = targets.to('cpu').numpy()\n",
    "\n",
    "            predictions.extend(list(np.argmax(logits, axis=1).flatten()))\n",
    "            ground_truth.extend(list(target_ids.flatten()))\n",
    "\n",
    "    print(classification_report(ground_truth, predictions, labels=[0, 1, 2, 3]))\n",
    "    print(\"\\nEvaluating loss: \" + str(eval_loss/len(validating_loader)) + \"\\n\")\n",
    "\n",
    "    accuracy = accuracy_score(ground_truth, predictions)\n",
    "    print(\"\\nAccuracy: \" + str(accuracy))\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        torch.save(model, '../models/bert_model.pth')\n",
    "        best_accuracy = accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-29T10:32:46.250797Z",
     "iopub.status.busy": "2024-03-29T10:32:46.250394Z",
     "iopub.status.idle": "2024-03-29T10:32:46.399957Z",
     "shell.execute_reply": "2024-03-29T10:32:46.398935Z",
     "shell.execute_reply.started": "2024-03-29T10:32:46.250769Z"
    },
    "id": "yWhgkhDP2WhW",
    "outputId": "d81e05c8-beca-4328-f442-21c6cbebf5bd",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = torch.load('../models/bert_model.pth',map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "X4Z57Lgi2WhW",
    "outputId": "55e76e5a-3d52-4016-ca1d-8875f3149666"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Korisnik\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "example = df.sample(1)\n",
    "ids, masks = tokenize_funciton(example.sentence.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mkaB9Fvs2WhW"
   },
   "outputs": [],
   "source": [
    "def map_result(value):\n",
    "    if value == 0:\n",
    "        return \"super positiv\"\n",
    "    elif value == 1:\n",
    "        return \"positiv\"\n",
    "    elif value == 3:\n",
    "        return \"negativ\"\n",
    "    else:\n",
    "        return \"super negativ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XWC6H3I72WhX",
    "outputId": "7c540ead-4e55-47f2-ac24-c8463b2ee0b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : positiv | truth : positiv\n"
     ]
    }
   ],
   "source": [
    "output= model(ids,\n",
    "            token_type_ids=None,\n",
    "            attention_mask=masks)\n",
    "\n",
    "logits = output.logits\n",
    "logits = logits.detach().cpu().numpy()\n",
    "pred_flat = np.argmax(logits, axis=1).flatten()\n",
    "\n",
    "for i in range(0,len(pred_flat)):\n",
    "    print(\"prediction : \" + str(map_result(pred_flat[i])) + \" | truth : \" + str(map_result(example.popularity.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmiLdKIV2WhX"
   },
   "source": [
    "Bert model korišćen je za predikciju popularnosti youtube snimka na osnovu naziva videa, naziva kanala, opisa i tagova. Zaključeno je da su sve 4 kolone bitne i utiču na tačnost modela.\n",
    "\n",
    "Vrednosti ove četri kolone spoje se u jednu rečenecu koja je ulaz u bert model a izlaz predstavlja popularnost određenu na osnovu procenta broja dislajkove u odnosu na lajkove.\n",
    "\n",
    "Nad ulaznim podacima radi se tokenziacija, stemovanje i padding kako bi model što više naučio o sličnosti između reči.\n",
    "\n",
    "Što se tiče parametara, learning rate kada je 1e-5 i 2e-5 daje isti rezultat a sve veće dovodi do loše tačnosti. Zbog velike količine podataka korišćen je AdamW optimizator ali je testirano i sa SGD koji je dao duplo gori rezultat. Batch size je uticao sasvim minimalno na model, nije davao veće razlike u tačnosti, razlika je u 1% gore ako se koristi veći batch_size.\n",
    "\n",
    "Trening i test podaci podeljeni su u odnosu 80:20.\n",
    "\n",
    "U početku je model davao slabu tačnost od svega 58% i na osnovu recall metrike zaključeno je da postoji nedostatak podataka u određenim klasama i onda su dodatno ubačeni podaci o video snimcima pre 2017 godine za klase koje su davale nizak recall. Model je posle toga dao bolju tačnost od 67%.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "saturn (Python 3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
